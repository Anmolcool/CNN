{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anmolcool/CNN/blob/main/Transfer_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rJJFW5HG8mg"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d salader/dogs-vs-cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFhmevm6HAIH",
        "outputId": "ce85e218-3a61-449e-eceb-c7a0f44935e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Downloading dogs-vs-cats.zip to /content\n",
            " 98% 1.05G/1.06G [00:06<00:00, 195MB/s]\n",
            "100% 1.06G/1.06G [00:06<00:00, 187MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipref = zipfile.ZipFile('/content/dogs-vs-cats.zip')\n",
        "zipref.extractall('/content')\n",
        "zipref.close()"
      ],
      "metadata": {
        "id": "_bmXyZ-eHALZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction - Transfer Learning"
      ],
      "metadata": {
        "id": "0AxW7D7XII8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "# Existing model - VGG16\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "8paLJmMQIAcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base = VGG16(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rkd3FNBHAOX",
        "outputId": "1a24d340-aa67-4052-fa9f-421095343160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.trainable = False\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  layer.trainable = False\n",
        "for layer in conv_base.layers:\n",
        "  print(layer.name, layer.trainable)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsiRz_3qKr02",
        "outputId": "612b9bca-f387-46fc-a1ce-e9254e065834"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_1 False\n",
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block1_pool False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block2_pool False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block3_pool False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block4_pool False\n",
            "block5_conv1 False\n",
            "block5_conv2 False\n",
            "block5_conv3 False\n",
            "block5_pool False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation ='sigmoid'))"
      ],
      "metadata": {
        "id": "yzm4VvZIHARD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import img_to_array, array_to_img, load_img"
      ],
      "metadata": {
        "id": "cWYnAoKhHAUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/content/train', target_size=(224,224),\n",
        "                                                    batch_size=batch_size, class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory('/content/test', target_size=(224,224),\n",
        "                                                    batch_size=batch_size, class_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icmwaKHlHAW0",
        "outputId": "c380651d-532e-406d-b49b-002ccffea3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20000 images belonging to 2 classes.\n",
            "Found 5000 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "d6OUgtbrHAZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit_generator(train_generator, validation_data= validation_generator, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QFYSRh0HAcw",
        "outputId": "56eaab1e-ac66-44c6-aa36-89898e9cd148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-02180e9b61e1>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_generator, validation_data= validation_generator, epochs=5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 309s 474ms/step - loss: 0.2837 - accuracy: 0.8892 - val_loss: 0.1577 - val_accuracy: 0.9336\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 294s 470ms/step - loss: 0.1866 - accuracy: 0.9215 - val_loss: 0.1557 - val_accuracy: 0.9386\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 292s 466ms/step - loss: 0.1717 - accuracy: 0.9287 - val_loss: 0.1525 - val_accuracy: 0.9346\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 292s 467ms/step - loss: 0.1535 - accuracy: 0.9352 - val_loss: 0.1979 - val_accuracy: 0.9174\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 292s 467ms/step - loss: 0.1498 - accuracy: 0.9392 - val_loss: 0.1402 - val_accuracy: 0.9376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cgElkYHDHAfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CPHxkGUQHAie"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}